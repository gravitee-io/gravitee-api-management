#
# Copyright Â© 2015 The Gravitee team (http://gravitee.io)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

version: '3.8'

networks:
  frontend:
    name: frontend
  storage:
    name: storage
  kafka:
    name: kafka
  email:
    name: email
  gateway:
    name: gateway

volumes:
  data-elasticsearch:
  data-mongo:
  data-kafka: null

services:
  mongodb:
    image: mongo:${MONGODB_VERSION:-6.0}
    container_name: gio_apim_mongodb
    restart: always
    volumes:
      - data-mongo:/data/db
      - ./.logs/apim-mongodb:/var/log/mongodb
    healthcheck:
      test: mongosh --eval 'db.runCommand({serverStatus:1}).ok' --quiet | grep 1
      interval: 5s
      timeout: 3s
      retries: 10
    networks:
      - storage

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION:-8.17.2}
    container_name: gio_apim_elasticsearch
    restart: always
    ports:
      - "9200:9200"
    volumes:
      - data-elasticsearch:/usr/share/elasticsearch/data
    environment:
      - http.host=0.0.0.0
      - transport.host=0.0.0.0
      - xpack.security.enabled=false
      - cluster.name=elasticsearch
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile: 65536
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=5s" ]
      interval: 5s
      timeout: 3s
      retries: 10
    networks:
      - storage

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.1-arm64
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - storage

  gateway:
    image: ${APIM_REGISTRY:-graviteeio}/apim-gateway:${APIM_VERSION:-latest}
    container_name: gio_apim_gateway
    restart: always
    ports:
      - "8082:8082"
      - "9092:9092"
    depends_on:
      mongodb:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./.logs/apim-gateway:/opt/graviteeio-gateway/logs
      - ./.license:/opt/graviteeio-gateway/license
      - ./.ssl:/opt/graviteeio-gateway/ssl
#      - ./.hosts:/etc/hosts
      - ./.config/logback.xml:/opt/graviteeio-gateway/config/logback.xml
    environment:
      - gravitee_management_mongodb_uri=mongodb://mongodb:27017/gravitee?serverSelectionTimeoutMS=5000&connectTimeoutMS=5000&socketTimeoutMS=5000
      - gravitee_ratelimit_mongodb_uri=mongodb://mongodb:27017/gravitee?serverSelectionTimeoutMS=5000&connectTimeoutMS=5000&socketTimeoutMS=5000
      - gravitee_reporters_elasticsearch_endpoints_0=http://elasticsearch:9200
#      Enable Kafka
      - gravitee_kafka_enabled=true
      - gravitee_kafka_ssl_keystore_password=gravitee
      - gravitee_kafka_ssl_keystore_path=$${gravitee.home}/ssl/server.keystore.jks
      - gravitee_kafka_ssl_keystore_type=jks
      - "gravitee_kafka_routingHostMode_defaultDomain=kafka.local"
    networks:
      storage:
      frontend:
      kafka:
      gateway:
        aliases:
#          Configure Docker DNS for possible API host
#          Only 2 API prefix hosts are possible by default in this example: foo and bar. And use the wildcard self-signed certificate matching *.kafka.local
#          To add more, add the new 2 lines following the pattern. Limitation due to our simplified example in docker
          - foo.kafka.local          # For kafka client this is the bootstrap server
          - broker-0-foo.kafka.local # Used by the kafka client internally after the initial connection to produce/consume messages for example
          - bar.kafka.local
          - broker-0-bar.kafka.local

  management_api:
    image: ${APIM_REGISTRY:-graviteeio}/apim-management-api:${APIM_VERSION:-latest}
    container_name: gio_apim_management_api
    restart: always
    ports:
      - "8083:8083"
    links:
      - mongodb
      - elasticsearch
    depends_on:
      mongodb:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./.logs/apim-management-api:/opt/graviteeio-management-api/logs
      - ./.license:/opt/graviteeio-management-api/license
    environment:
      - gravitee_management_mongodb_uri=mongodb://mongodb:27017/gravitee?serverSelectionTimeoutMS=5000&connectTimeoutMS=5000&socketTimeoutMS=5000
      - gravitee_analytics_elasticsearch_endpoints_0=http://elasticsearch:9200
      - gravitee_email_enabled=true
      - gravitee_email_host=mailhog
      - gravitee_email_port=1025
      - gravitee_email_subject="TEST"
      - gravitee_email_from="user@my.domain"
    networks:
      - storage
      - frontend
      - email

  management_ui:
    image: ${APIM_REGISTRY:-graviteeio}/apim-management-ui:${APIM_VERSION:-latest}
    container_name: gio_apim_management_ui
    restart: always
    ports:
      - "8084:8080"
    depends_on:
      - management_api
    environment:
      - MGMT_API_URL=http://localhost:8083/management/
    volumes:
      - ./.logs/apim-management-ui:/var/log/nginx
    networks:
      - frontend

  portal_ui:
    image: ${APIM_REGISTRY:-graviteeio}/apim-portal-ui:${APIM_VERSION:-latest}
    container_name: gio_apim_portal_ui
    restart: always
    ports:
      - "8085:8080"
    depends_on:
      - management_api
    environment:
      - PORTAL_API_URL=http://localhost:8083/portal
    volumes:
      - ./.logs/apim-portal-ui:/var/log/nginx
    networks:
      - frontend

  mailhog:
    image: mailhog/mailhog
    container_name: gio_apim_mailhog
    restart: always
    ports:
      - "8025:8025"
      - "1025:1025"
    networks:
      - email

  kafka:
    image: docker.io/bitnami/kafka:3.9
    container_name: gio_apim_kafka
    volumes:
      - data-kafka:/bitnami/kafka
      - "./.ssl/server.keystore.jks:/opt/bitnami/kafka/config/certs/kafka.keystore.jks:ro"
      - "./.ssl/server.truststore.jks:/opt/bitnami/kafka/config/certs/kafka.truststore.jks:ro"
    ports:
      - "9091:9091"
      - "9093:9093"
      - "9094:9094"
      - "9095:9095"
      - "9096:9096"
      - "9097:9097"
    networks:
      - kafka
    environment:
      - BITNAMI_DEBUG=true
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@localhost:9093
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9091,CONTROLLER://:9093,SSL://:9094,SASL_PLAINTEXT://:9095,SASL_SSL://:9096,KAFDROP://:9097
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9091,SSL://kafka:9094,SASL_PLAINTEXT://kafka:9095,SASL_SSL://kafka:9096,KAFDROP://kafka:9097
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,KAFDROP:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=PLAIN
      - KAFKA_CFG_SASL_ENABLED_MECHANISMS=PLAIN,SCRAM-SHA-256,SCRAM-SHA-512,OAUTHBEARER
      - KAFKA_CFG_LISTENER_NAME_SASL_PLAINTEXT_OAUTHBEARER_SASL_JAAS_CONFIG=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;
      - KAFKA_CFG_LISTENER_NAME_SASL_PLAINTEXT_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS=org.apache.kafka.common.security.oauthbearer.OAuthBearerValidatorCallbackHandler
      - KAFKA_CFG_LISTENER_NAME_SASL_SSL_OAUTHBEARER_SASL_JAAS_CONFIG=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;
      - KAFKA_CFG_LISTENER_NAME_SASL_SSL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS=org.apache.kafka.common.security.oauthbearer.OAuthBearerValidatorCallbackHandler
      - KAFKA_CFG_SASL_OAUTHBEARER_JWKS_ENDPOINT_URL=https://am.gateway.master.gravitee.dev/test-jh/oidc/.well-known/jwks.json
      - KAFKA_CFG_SASL_OAUTHBEARER_EXPECTED_AUDIENCE=kafka-client
      - KAFKA_NUM_PARTITIONS=1
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      # SASL settings
      - KAFKA_CLIENT_USERS=gravitee_user
      - KAFKA_CLIENT_PASSWORDS=gravitee_password
      - KAFKA_CONTROLLER_USER=controller_user
      - KAFKA_CONTROLLER_PASSWORD=controller_password
      - KAFKA_INTER_BROKER_USER=inter_broker_user
      - KAFKA_INTER_BROKER_PASSWORD=inter_broker_password
      # Certificate credentials
      - KAFKA_CFG_SSL_KEYSTORE_LOCATION=/opt/bitnami/kafka/config/certs/kafka.keystore.jks
      - KAFKA_CFG_SSL_KEYSTORE_PASSWORD=gravitee
      - KAFKA_CFG_SSL_TRUSTSTORE_LOCATION=/opt/bitnami/kafka/config/certs/kafka.truststore.jks
      - KAFKA_CFG_SSL_TRUSTSTORE_PASSWORD=gravitee
      - KAFKA_TLS_CLIENT_AUTH=requested
      - KAFKA_CERTIFICATE_PASSWORD=gravitee
      - KAFKA_TLS_TYPE=JKS
      - KAFKA_CFG_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/9097"]
      interval: 5s # Check every 10 seconds
      timeout: 10s # Timeout after 10 seconds
      retries: 5 # Retry up to 5 times
      start_period: 10s # Wait 30 seconds before starting health checks

  kafka-ui:
    container_name: gio_apim_kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "9003:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9097
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - kafka

  kafka-client:
    image: docker.io/bitnami/kafka:3.9
    container_name: gio_apim_kafka-client
    volumes:
      - ./.kafka-client-config:/app/config
      - ./.ssl:/app/.ssl
    depends_on:
      - gateway
    entrypoint: ["tail", "-f", "/dev/null"]
    working_dir: /app
    networks:
      - gateway
